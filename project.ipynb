{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project FDS\n",
    "\n",
    "Bone fracture detection on x-ray images using a CNN.\n",
    "\n",
    "Group members: Aiman Nadeem, Thale Krohn-Pettersen, Kirsten Nord.\n",
    "\n",
    "## Table of contents\n",
    "1. [Setup and data preprocessing](#setup)\n",
    "2. [Model definition](#model)\n",
    "3. [Training and validation](#training)\n",
    "4. [Analysis](#analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and data preprocessing <a name=\"setup\"></a>\n",
    "\n",
    "- Installing required packages\n",
    "- Importing necessary libraries\n",
    "- Downloading dataset and re-splitting the dataset into 80% training, 10% validation and 10% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.5-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.1.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.1-cp38-cp38-macosx_10_9_universal2.whl.metadata (164 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp38-cp38-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /Users/thalekp/miniconda3/envs/tf_env/lib/python3.8/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/thalekp/miniconda3/envs/tf_env/lib/python3.8/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/thalekp/miniconda3/envs/tf_env/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/thalekp/miniconda3/envs/tf_env/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/thalekp/miniconda3/envs/tf_env/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/thalekp/miniconda3/envs/tf_env/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached matplotlib-3.7.5-cp38-cp38-macosx_11_0_arm64.whl (7.3 MB)\n",
      "Using cached contourpy-1.1.1-cp38-cp38-macosx_11_0_arm64.whl (232 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.1-cp38-cp38-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading kiwisolver-1.4.7-cp38-cp38-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.55.1 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.7.5 pyparsing-3.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    #%pip install kagglehub scikit-learn\n",
    "    #%pip install tensorflow\n",
    "    #%pip install pillow\n",
    "    %pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import kagglehub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Dataset downloaded to /Users/thalekp/.cache/kagglehub/datasets/osamajalilhassan/bone-fracture-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset from Kaggle\n",
    "dataset_path = kagglehub.dataset_download(\"osamajalilhassan/bone-fracture-dataset\")\n",
    "print(f\"Dataset downloaded to {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into train, validation, and test sets at data\n"
     ]
    }
   ],
   "source": [
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff'))\n",
    "\n",
    "def split_dataset(dataset_path, output_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    os.makedirs(output_path, exist_ok=True)  # Ensure output directory exists\n",
    "\n",
    "    splits = ['training', 'testing']\n",
    "    categories = ['fractured', 'not_fractured']\n",
    "\n",
    "    for split in splits:\n",
    "        for category in categories:\n",
    "            class_dir = os.path.join(dataset_path, split, category)\n",
    "            \n",
    "            # Get all image files in the category\n",
    "            images = [f for f in os.listdir(class_dir) if is_image_file(f)]\n",
    "            random.shuffle(images)\n",
    "\n",
    "            # Calculate split sizes\n",
    "            train_end = int(len(images) * train_ratio)\n",
    "            val_end = train_end + int(len(images) * val_ratio)\n",
    "\n",
    "            train_images = images[:train_end]\n",
    "            val_images = images[train_end:val_end]\n",
    "            test_images = images[val_end:]\n",
    "\n",
    "            # Create subdirectories for train, val, test\n",
    "            for split_name, split_images in zip(\n",
    "                ['train', 'val', 'test'], [train_images, val_images, test_images]\n",
    "            ):\n",
    "                split_dir = os.path.join(output_path, split_name, category)\n",
    "                os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "                # Copy images to respective split folder\n",
    "                for image in split_images:\n",
    "                    src = os.path.join(class_dir, image)\n",
    "                    dst = os.path.join(split_dir, image)\n",
    "                    try:\n",
    "                        shutil.copy(src, dst)\n",
    "                    except PermissionError as e:\n",
    "                        print(f\"Skipping {src} due to permission error: {e}\")\n",
    "                        \n",
    "    print(f\"Dataset split into train, validation, and test sets at {output_path}\")\n",
    "\n",
    "# Perform the dataset split\n",
    "dataset_path = dataset_path + \"/BoneFractureDataset\"\n",
    "output_path = \"data\"\n",
    "split_dataset(dataset_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying dataset split...\n",
      "Number of images in train split:\n",
      "  Total images in train: 9461\n",
      "Number of images in val split:\n",
      "  Total images in val: 3871\n",
      "Number of images in test split:\n",
      "  Total images in test: 3904\n"
     ]
    }
   ],
   "source": [
    "def count_images_in_split(split_path):\n",
    "    # Count the number of image files in a given split directory (train, val, or test)\n",
    "    total_images = 0\n",
    "    for category in ['fractured', 'not_fractured']:\n",
    "        category_path = os.path.join(split_path, category)\n",
    "        if os.path.exists(category_path):\n",
    "            category_images = os.listdir(category_path)\n",
    "            total_images += len(category_images)\n",
    "    return total_images\n",
    "\n",
    "def verify_split(output_path):\n",
    "    # Verify the directory structure and the number of images in each split\n",
    "    splits = ['train', 'val', 'test']\n",
    "    print(\"Verifying dataset split...\")\n",
    "\n",
    "    for split in splits:\n",
    "        split_path = os.path.join(output_path, split)\n",
    "        if os.path.exists(split_path):\n",
    "            print(f\"Number of images in {split} split:\")\n",
    "            num_images = count_images_in_split(split_path)\n",
    "            print(f\"  Total images in {split}: {num_images}\")\n",
    "        else:\n",
    "            print(f\"  No {split} directory found!\")\n",
    "\n",
    "# Perform the verification\n",
    "verify_split(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition <a name=\"model\"></a>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "base_dir = output_path\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9461 images belonging to 2 classes.\n",
      "Found 3871 images belonging to 2 classes.\n",
      "Found 3904 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),  # Resize images to 150x150\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification: fractured or not\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation <a name=\"training\"></a>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 81s 272ms/step - loss: 0.6931 - accuracy: 0.5481 - precision: 0.5397 - recall: 0.5114 - val_loss: 0.6499 - val_accuracy: 0.6143 - val_precision: 0.5877 - val_recall: 0.7079\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thalekp/miniconda3/envs/tf_env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('fracture_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis <a name=\"analysis\"></a>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 9s 70ms/step - loss: 0.6484 - accuracy: 0.6109 - precision: 0.5837 - recall: 0.6977\n",
      "Accuracy: 0.61\n",
      "Precision: 0.5837\n",
      "Recall: 0.6977\n",
      "F1 Score: 0.6356\n"
     ]
    }
   ],
   "source": [
    "loss, acc, precision, recall  = model.evaluate(test_generator)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
